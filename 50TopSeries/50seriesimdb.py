# -*- coding: utf-8 -*-
"""50SeriesIMDB.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cmaq0tY8ymOk4NImL82vpdE1AspzZUam
"""

import requests
import pandas as pd
import numpy as np
!pip install more_itertools

!pip install more_itertools
from more_itertools import chunked

page = requests.get('https://www.imdb.com/search/title/?title_type=tv_series&release_date=2020-01-01,2021-12-31&countries=us')

page.status_code

from http.client import responses
responses[page.status_code]

from bs4 import BeautifulSoup
soup = BeautifulSoup(page.content, 'html.parser')

serials = soup.select('.lister-item-header a')
print('{} links found!'.format(len(serials)))

serials

serial_name = [serial.text for serial in serials]
df_title = pd.DataFrame(serial_name, columns =['Title'])
df_title

serial_url = [serial.get('href') for serial in serials]
new_serial_url = []
for i in serial_url:
    s = 'http://www.imdb.com'+i
    new_serial_url.append(s)
new_serial_url

def remove_last_character(string):
    if string:
        string = string[:-1]
    return string
m=[]
for i in new_serial_url:
    updated_string = remove_last_character(i)
    m.append(updated_string)
df_url = pd.DataFrame(m, columns =['Link'])
df_url

runtimes = soup.select('.runtime')
runtime_txt=[runtime.text for runtime in runtimes]
runtime_txt

runtime_txt.insert(11, np.NaN)

runtime_txt.insert(19, np.NaN)

runtime_txt.insert(25, np.NaN)

runtime_txt.insert(32, np.NaN)

runtime_txt.insert(39, np.NaN)

runtime_txt.insert(43, np.NaN)

df_runtime = pd.DataFrame(runtime_txt, columns =['Runtime'])
df_runtime

genres = soup.select('.genre')
genre_txt=[genre.text for genre in genres]
genre_txt

u=[]
for i in genre_txt:
    o = i.replace(' ','')
    u.append(o)
f=[]
for i in u:
    s = i.replace('\n','')
    f.append(s)

c = []
for i in f:
    a = i.strip('()').split(',')
    c.append(a)

df_genres = pd.DataFrame(columns = ['Genres'])

for i in range(50):
    df_genres.at[i,'Genres'] = c[i]
df_genres

headlines = soup.select('.text-muted+ p a')
headlines_txt=[headline.text for headline in headlines]
u=[]
for i in headlines_txt:
    o = i.replace(' ','')
    u.append(o)
f=[]
for i in u:
    s = i.replace('\n','')
    f.append(s)

f

from more_itertools import chunked

def split_list(lst, size):
    return list(chunked(lst, size))
split_lists = split_list(u, 4)

split_lists

df_stars = pd.DataFrame(columns = ['Stars'])

for i in range(50):
    df_stars.at[i,'Stars'] = split_lists[i]
df_stars

cers = soup.select('.certificate')
cers

parental = [cer.text for cer in cers]
df_parent = pd.DataFrame(parental, columns =['Parental Guidelines'])
df_parent

horizontal_concat = pd.concat([df_title, df_url , df_runtime,df_genres,df_parent,df_stars], axis=1)
horizontal_concat

horizontal_concat.to_csv('50_top_series_2020.csv', index=False)